{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import tweepy as tw\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "import csv\n",
    "import numpy as np\n",
    "import string\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "run_stamp = dt.now().strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials accepted; you're good to go!\n"
     ]
    }
   ],
   "source": [
    "# Read in Twitter API keys and token information from stored environment variables\n",
    "api_key = os.environ.get('TWITTER_API_KEY')\n",
    "api_secret = os.environ.get('TWITTER_API_SECRET')\n",
    "access_token_key = os.environ.get('TWITTER_ACCESS_TOKEN_KEY')\n",
    "access_token_secret = os.environ.get('TWITTER_ACCESS_TOKEN_SECRET')\n",
    "\n",
    "# Pass API keys and tokens to initialize API\n",
    "\n",
    "auth = tw.OAuthHandler(api_key, api_secret)\n",
    "auth.set_access_token(access_token_key, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit = True)\n",
    "\n",
    "try: \n",
    "    api.verify_credentials()\n",
    "    print(\"Credentials accepted; you're good to go!\")\n",
    "except: \n",
    "    print(\"Hmm. Something is wrong here. Twitter couldn't authenticate your account with the information provided.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "parent = os.path.dirname(current)\n",
    "candidate_folder = \"\\\\sourcing_general_election_candidates\\\\general_election_candidates_state\\\\\"\n",
    "list_of_candidates_path = parent + candidate_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory to read-in .txt files containing a list of candidates in a given state\n",
    "os.chdir(list_of_candidates_path)\n",
    "\n",
    "# Initialize an empty list that will hold information on our candidates\n",
    "candidates_for_analysis = []\n",
    "\n",
    "def read_text_file(file_path): \n",
    "\n",
    "    \"\"\"\n",
    "    This function opens each file that ends in .txt, and appends the information to the list above. \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    with open(file_path, 'r') as f: \n",
    "        for line in f:\n",
    "            candidates_for_analysis.append(line.strip())\n",
    "\n",
    "for file in os.listdir(): \n",
    "    if file.endswith(\".txt\"): \n",
    "        file_path = f'{list_of_candidates_path}{file}' # Uses f-string to navigate to the correct folder \n",
    "        read_text_file(file_path) # Calls the function to read in .txt files\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Candidates for a given state were sourced using the Wikimedia API. The information returned is a list of lists.\n",
    "As structured, this cannot be fed to the API to find Twitter accounts. \n",
    "Instead, convert the list of lists to a string, then replace extraneous / offending characters appropriately.\n",
    "Finally, remove the last two characters of the string -- they will be \", \".\n",
    "\n",
    "\"\"\"       \n",
    "\n",
    "candidate_string_result = ' '.join([str(element) for element in candidates_for_analysis])\n",
    "candidate_string_result = candidate_string_result.replace(\"['\", '')\n",
    "candidate_string_result = candidate_string_result.replace(\" ']\", ', ')\n",
    "candidate_string_result = candidate_string_result[:-2]\n",
    "\n",
    "def convert_clean_names_to_list(string): \n",
    "\n",
    "    \"\"\"\n",
    "    This function converts the cleaned names back to a list that can be passed to Twitter. \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    list_of_strings = list(string.split(\", \"))\n",
    "    return list_of_strings\n",
    "\n",
    "candidate_list = convert_clean_names_to_list(candidate_string_result) # Convert the strings back to a list\n",
    "\n",
    "file_state = file.split(\"_\", 1)[0] # Select the state name from the parent file\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Since Twitter's API does not currently allow users to see / differentiate accounts based on  the Election Label --\n",
    "https://help.twitter.com/en/using-twitter/election-labels -- we must query Twitter to return a list accounts\n",
    "that may be a general election candidate. \n",
    "\n",
    "This is an involved process. Given our list of general election candidate names (candidate_string_result), \n",
    "we pass those names in for loops to Twitter to return a set of account-specific information that we use to \n",
    "manually process, differentiate, and discern account IDs for general election candidates -- e.g., the primary target. \n",
    "\n",
    "Specifically, we request screen names, ids, locations, url, and descriptions for each probable account returned by Twitter. \n",
    "Next, these are zipped into a list wherein the information is grouped by position. \n",
    "That is, all info in index position 5 in all lists are grouped together. \n",
    "\n",
    "Now, manually review each row for information to determine which account is a general election candidate. \n",
    "This process will differ from state to state, with drops determined by specific place in index of true candidates.\n",
    "\n",
    "Until such time Twitter includes the ability to query this information via the API, manual processing is requried. \n",
    "That said, this is an open question: \n",
    "https://twittercommunity.com/t/share-your-input-on-adding-tweet-profile-labels-to-the-twitter-api-v2/167678.\n",
    "\n",
    "\"\"\"\n",
    "# Initialize empty lists to hold account information about possible candidate Twitter accounts\n",
    "potential_candidate_accounts = []\n",
    "potential_candidate_account_ids = []\n",
    "potential_candidate_account_location = []\n",
    "potential_candidate_account_url = []\n",
    "potential_candidate_account_description = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "# While there are still potentials candidates in the candidate_list\n",
    "while counter < len(candidate_list): \n",
    "    for user in candidate_list: \n",
    "        accounts = api.search_users(user) # Call the API to search for users with similar names\n",
    "        for account in accounts: \n",
    "            potential_candidate_accounts.append(account.screen_name) # Append screen name to the relevant list\n",
    "            potential_candidate_account_ids.append(account.id_str) # Append ID to the relevant list\n",
    "            potential_candidate_account_location.append(account.location) # Append location to the relevant list\n",
    "            potential_candidate_account_url.append(account.url) # Append url in profile to the relevant list\n",
    "            potential_candidate_account_description.append(account.description) # Append description to the relevant list\n",
    "            \n",
    "            counter += 1 # Increment through list until exhausted\n",
    "            \n",
    "# Instantiate a list that is the same length as the list we passed to Twitter with the state name as the only value\n",
    "potential_candidate_accounts_state_analysis = [file_state] * len(potential_candidate_accounts)\n",
    "\n",
    "# Zip the lists into another list, so each place in index aligns to the same potential candidate\n",
    "zipped_candidate_list = list(zip(potential_candidate_accounts, \n",
    "                        potential_candidate_account_ids, \n",
    "                        potential_candidate_account_location, \n",
    "                        potential_candidate_account_url, \n",
    "                        potential_candidate_account_description,\n",
    "                        potential_candidate_accounts_state_analysis))\n",
    "\n",
    "# Convert zipped list to dataframe, initialize column names as appropriate\n",
    "candidate_twitter_info = pd.DataFrame(data = zipped_candidate_list, columns = ['SCREEN_NAME', 'ACCOUNT_ID', 'LOCATION', 'URL', 'DESCRIPTION', 'STATE'])\n",
    "candidate_twitter_info = pd.DataFrame(candidate_twitter_info)\n",
    "\n",
    "# Drop non-target accounts from the dataframe based on index position\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[1:15], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[3:23], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[4:22], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[5:12], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[5], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[7:25], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[8:47], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[10:28], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[12:17], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[16], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[18:36], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[19:31], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[20:39], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[23:43], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[24:41], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[25], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[21:23], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[24:60], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[25], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[26:44], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[27:45], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[29:32], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[31:49], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[32:51], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[34:52], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[35:54], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[37:55], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[38:77], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[39:58], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[40:59], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[42:60], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[43:45], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[45:62], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[46:54], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[48:53], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[50:68], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[54:72], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[55:74], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[57:76], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[58:99], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[59:62], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[61:79], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[62:81], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[64:69], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[65:88], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[66:87], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[67:84], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[69:87], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[70:89], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[72:110], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[74:134], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[76:93], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[78:96], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[80:89], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[81:86], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[82:98], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[84:104], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[86:104], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[87:126], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[89:107], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[90:95], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[92:94], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[93:113], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info.drop(candidate_twitter_info.index[94:114], axis = 0, inplace = True)\n",
    "candidate_twitter_info.reset_index(level = 0, inplace = True, drop = True)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "The search to surface potential general election candidates wasn't 100 % accurate. \n",
    "So given the list of candidates obtained from the Wikimedia API, we manually searched to see if a given \n",
    "candidate in fact had a Twitter account. For those that do have accounts, \n",
    "instantiate a list of their handles to pass to Twitter once again and repeat the process above. \n",
    "\n",
    "As of the date of execution, 10 candidates for Congress in Texas did not have Twitter accounts, including: \n",
    "Jimmy leon, Jamie Kaye Jordan, Robert Schafranek, Julio Garza, James Harris, Patrick Gillespie, \n",
    "Dan McQueen, Michael Rodriguez, Rod Lingsch, and Duncan Klussman. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "manual_candidate_list = ['sandeepfortexas', \n",
    "                         'rubentx15', \n",
    "                         'RVillarrealTX21', \n",
    "                         'derrikgay', \n",
    "                         'JCisnerosTX', \n",
    "                         'texas_sandra', \n",
    "                         'CasandraLGarcia', \n",
    "                         'JasmineForUS', \n",
    "                         'JaneHopeTX',\n",
    "                         'GregCasar', \n",
    "                         'DianaforTexas'\n",
    "                        ]\n",
    "\n",
    "# Initialize empty lists to hold account information about possible candidate Twitter accounts\n",
    "manual_potential_candidate_accounts = []\n",
    "manual_potential_candidate_account_ids = []\n",
    "manual_potential_candidate_account_location = []\n",
    "manual_potential_candidate_account_url = []\n",
    "manual_potential_candidate_account_description = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "# While there are still potentials candidates in the candidate_list\n",
    "while counter < len(manual_candidate_list): \n",
    "    for user in manual_candidate_list: \n",
    "        accounts = api.search_users(user)\n",
    "        for account in accounts: \n",
    "            manual_potential_candidate_accounts.append(account.screen_name) # Append screen name to the relevant list\n",
    "            manual_potential_candidate_account_ids.append(account.id_str) # Append id to the relevant list\n",
    "            manual_potential_candidate_account_location.append(account.location) # Append location in profile to the relevant list\n",
    "            manual_potential_candidate_account_url.append(account.url) # Append url in profile to the relevant list\n",
    "            manual_potential_candidate_account_description.append(account.description) # Append description in profile to the relevant list\n",
    "            \n",
    "            counter += 1 # Increment through list until exhausted\n",
    "\n",
    "# Instantiate a list that is the same length as the list we passed to Twitter with the state name as the only value\n",
    "manual_potential_candidate_accounts_state_analysis = [file_state] * len(manual_potential_candidate_accounts)\n",
    "\n",
    "# Zip the lists into another list, so each place in index aligns to the same potential candidate\n",
    "manual_zipped_manual_candidate_list = list(zip(manual_potential_candidate_accounts, \n",
    "                        manual_potential_candidate_account_ids, \n",
    "                        manual_potential_candidate_account_location, \n",
    "                        manual_potential_candidate_account_url, \n",
    "                        manual_potential_candidate_account_description,\n",
    "                        manual_potential_candidate_accounts_state_analysis))\n",
    "\n",
    "# Convert zipped list to dataframe, initialize column names as appropriate\n",
    "manual_candidate_twitter_info = pd.DataFrame(data = manual_zipped_manual_candidate_list, columns = ['SCREEN_NAME', 'ACCOUNT_ID', 'LOCATION', 'URL', 'DESCRIPTION', 'STATE'])\n",
    "candidate_twitter_info_manual = pd.DataFrame(manual_candidate_twitter_info)\n",
    "\n",
    "# Drop non-target accounts from the dataframe based on index position\n",
    "candidate_twitter_info_manual.drop(candidate_twitter_info_manual.index[4], axis = 0, inplace = True)\n",
    "candidate_twitter_info_manual.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info_manual.drop(candidate_twitter_info_manual.index[5:11], axis = 0, inplace = True)\n",
    "candidate_twitter_info_manual.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info_manual.drop(candidate_twitter_info_manual.index[6:25], axis = 0, inplace = True)\n",
    "candidate_twitter_info_manual.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info_manual.drop(candidate_twitter_info_manual.index[7], axis = 0, inplace = True)\n",
    "candidate_twitter_info_manual.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info_manual.drop(candidate_twitter_info_manual.index[11:14], axis = 0, inplace = True)\n",
    "candidate_twitter_info_manual.reset_index(level = 0, inplace = True, drop = True)\n",
    "candidate_twitter_info_manual.drop(candidate_twitter_info_manual.index[8], axis = 0, inplace = True)\n",
    "candidate_twitter_info_manual.reset_index(level = 0, inplace = True, drop = True)\n",
    "\n",
    "# Concat the two dataframes vertically, and then convert to a list that contains only their ACCOUNT_IDs \n",
    "# We pass this inforamtion to twitter in the get_followers_id function to source, append, and archive followers\n",
    "candidate_twitter_info = pd.concat([candidate_twitter_info, candidate_twitter_info_manual], axis=0, ignore_index=True)\n",
    "general_election_candidates_twitter_ids_list = candidate_twitter_info.ACCOUNT_ID.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 798\n",
      "Rate limit reached. Sleeping for: 898\n"
     ]
    }
   ],
   "source": [
    "for candidate in general_election_candidates_twitter_ids_list:\n",
    "    \n",
    "    follower_ids = []\n",
    "    \n",
    "    for ids_tweepy in tw.Cursor(api.get_follower_ids, user_id = candidate).pages(): \n",
    "        follower_ids.extend(ids_tweepy)\n",
    "    \n",
    "    path_to_output = current + \"\\\\\" + file_state + \"\\\\id_output\\\\\"\n",
    "\n",
    "    # Check whether the specified path exists or not\n",
    "    isExist = os.path.exists(path_to_output)\n",
    "\n",
    "    if not isExist:\n",
    "        os.makedirs(path_to_output)\n",
    "\n",
    "    path = current + \"\\\\\" + file_state + \"\\\\id_output\\\\\"+ \"{}_followers_{}.csv\".format(candidate, run_stamp)\n",
    "    to_write_file = path\n",
    "\n",
    "    with open(to_write_file, mode = 'a', newline = '') as csv_file:\n",
    "        writer = csv.writer(csv_file, dialect = 'excel')\n",
    "        for item in follower_ids: \n",
    "            writer.writerow([item])\n",
    "        csv_file.closed"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
